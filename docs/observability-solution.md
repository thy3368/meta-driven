# å®Œæ•´å¯è§‚æµ‹æ€§æ–¹æ¡ˆ

## ä¸€ã€æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           å¯è§‚æµ‹æ€§å¹³å°                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Metrics       â”‚      Logging      â”‚          Tracing                â”‚
â”‚    (æŒ‡æ ‡ç›‘æ§)      â”‚     (æ—¥å¿—ç³»ç»Ÿ)     â”‚         (é“¾è·¯è¿½è¸ª)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Prometheus      â”‚       Loki        â”‚           Tempo                 â”‚
â”‚       â†“           â”‚         â†“         â”‚             â†“                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚    Grafana    â”‚  â† ç»Ÿä¸€å¯è§†åŒ–é¢æ¿
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†‘
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
    /metrics            /logs (JSON)         Trace Context
    (Prometheus)        (Logback)            (OpenTelemetry)
         â”‚                    â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Spring Boot 4   â”‚
                    â”‚   meta-driven     â”‚
                    â”‚                   â”‚
                    â”‚ â€¢ Micrometer      â”‚
                    â”‚ â€¢ OTEL Tracing    â”‚
                    â”‚ â€¢ Logback JSON    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€æŠ€æœ¯é€‰å‹

| æ”¯æŸ± | é‡‡é›†ç«¯ | å­˜å‚¨ç«¯ | å¯è§†åŒ– | é€‰å‹ç†ç”± |
|------|--------|--------|--------|----------|
| **Metrics** | Micrometer | Prometheus | Grafana | ä¸šç•Œæ ‡å‡†ï¼Œä¸ Spring Boot æ·±åº¦é›†æˆ |
| **Logging** | Logback + JSON | Loki | Grafana | è½»é‡çº§ï¼Œä¸ Grafana ç”Ÿæ€ç»Ÿä¸€ |
| **Tracing** | Micrometer Tracing + OTEL | Tempo | Grafana | äº‘åŸç”Ÿæ ‡å‡†ï¼Œæ”¯æŒ TraceID å…³è” |

**å¤‡é€‰æ–¹æ¡ˆ**ï¼š
- Logging: ELK Stack (Elasticsearch + Logstash + Kibana) - åŠŸèƒ½æ›´å¼ºä½†èµ„æºæ¶ˆè€—å¤§
- Tracing: Jaeger / Zipkin - æˆç†Ÿç¨³å®šï¼Œä½† Tempo ä¸ Grafana é›†æˆæ›´å¥½

---

## ä¸‰ã€ä¾èµ–æ¸…å•

```xml
<!-- pom.xml æ–°å¢ä¾èµ– -->

<!-- 1. Actuator - æš´éœ²ç®¡ç†ç«¯ç‚¹ -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- 2. Prometheus Registry - æŒ‡æ ‡å¯¼å‡º -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>

<!-- 3. Micrometer Tracing + OpenTelemetry -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-exporter-otlp</artifactId>
</dependency>

<!-- 4. Logback JSON Encoder -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>8.0</version>
</dependency>
```

---

## å››ã€é…ç½®æ–¹æ¡ˆ

### 4.1 application.yml

```yaml
spring:
  application:
    name: meta-driven

# ============================================
# Actuator & Metrics é…ç½®
# ============================================
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,loggers
      base-path: /actuator
  endpoint:
    health:
      show-details: when_authorized
      probes:
        enabled: true  # Kubernetes æ¢é’ˆæ”¯æŒ
    prometheus:
      enabled: true

  metrics:
    distribution:
      percentiles-histogram:
        http.server.requests: true  # è¯·æ±‚å»¶è¿Ÿç›´æ–¹å›¾
      percentiles:
        http.server.requests: 0.5, 0.95, 0.99, 0.999  # P50/P95/P99/P999
      minimum-expected-value:
        http.server.requests: 1ms
      maximum-expected-value:
        http.server.requests: 10s
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:local}

# ============================================
# Tracing é…ç½® (OpenTelemetry)
# ============================================
  tracing:
    sampling:
      probability: 1.0  # ç”Ÿäº§ç¯å¢ƒå»ºè®® 0.1 (10% é‡‡æ ·)
    propagation:
      type: w3c  # W3C Trace Context æ ‡å‡†

  otlp:
    tracing:
      endpoint: http://tempo:4318/v1/traces  # Tempo OTLP HTTP ç«¯ç‚¹

# ============================================
# Logging é…ç½®
# ============================================
logging:
  level:
    root: INFO
    com.tanggo.fund: DEBUG
  pattern:
    correlation: "[${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
```

### 4.2 logback-spring.xml (ç»“æ„åŒ–æ—¥å¿—)

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>

    <!-- å±æ€§å®šä¹‰ -->
    <springProperty scope="context" name="APP_NAME" source="spring.application.name"/>
    <property name="LOG_PATH" value="${LOG_PATH:-./logs}"/>

    <!-- ============================================ -->
    <!-- æ§åˆ¶å°è¾“å‡º (å¼€å‘ç¯å¢ƒ) -->
    <!-- ============================================ -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} %highlight(%-5level) [%X{traceId:-},%X{spanId:-}] %cyan(%logger{36}) - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- ============================================ -->
    <!-- JSON æ ¼å¼è¾“å‡º (ç”Ÿäº§ç¯å¢ƒ - Loki/ELK) -->
    <!-- ============================================ -->
    <appender name="JSON_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/${APP_NAME}.json</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/${APP_NAME}.%d{yyyy-MM-dd}.json.gz</fileNamePattern>
            <maxHistory>7</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"app":"${APP_NAME}","env":"${ENVIRONMENT:-local}"}</customFields>
            <includeMdcKeyName>traceId</includeMdcKeyName>
            <includeMdcKeyName>spanId</includeMdcKeyName>
        </encoder>
    </appender>

    <!-- ============================================ -->
    <!-- å¼‚æ­¥æ—¥å¿— (ä½å»¶è¿Ÿä¼˜åŒ–) -->
    <!-- ============================================ -->
    <appender name="ASYNC_JSON" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>1024</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <neverBlock>true</neverBlock>
        <appender-ref ref="JSON_FILE"/>
    </appender>

    <!-- Profile é…ç½® -->
    <springProfile name="local,dev">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
        </root>
    </springProfile>

    <springProfile name="prod,staging">
        <root level="INFO">
            <appender-ref ref="ASYNC_JSON"/>
        </root>
    </springProfile>
</configuration>
```

---

## äº”ã€è‡ªå®šä¹‰æŒ‡æ ‡ç»„ä»¶

### 5.1 ä¸šåŠ¡æŒ‡æ ‡æ³¨å†Œ

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.core.instrument.*;
import org.springframework.stereotype.Component;
import java.util.concurrent.atomic.AtomicLong;

@Component
public class BusinessMetrics {

    private final Counter commandCounter;
    private final Counter queryCounter;
    private final Timer commandLatency;
    private final AtomicLong activeCommands;

    public BusinessMetrics(MeterRegistry registry) {
        // å‘½ä»¤è®¡æ•°å™¨
        this.commandCounter = Counter.builder("cqrs.commands.total")
            .description("Total commands processed")
            .tag("type", "command")
            .register(registry);

        // æŸ¥è¯¢è®¡æ•°å™¨
        this.queryCounter = Counter.builder("cqrs.queries.total")
            .description("Total queries processed")
            .tag("type", "query")
            .register(registry);

        // å‘½ä»¤å»¶è¿Ÿ Timer
        this.commandLatency = Timer.builder("cqrs.command.latency")
            .description("Command processing latency")
            .publishPercentiles(0.5, 0.95, 0.99, 0.999)
            .publishPercentileHistogram()
            .register(registry);

        // æ´»è·ƒå‘½ä»¤æ•° Gauge
        this.activeCommands = new AtomicLong(0);
        Gauge.builder("cqrs.commands.active", activeCommands, AtomicLong::get)
            .description("Currently active commands")
            .register(registry);
    }

    public void recordCommand(String commandName, Runnable execution) {
        activeCommands.incrementAndGet();
        try {
            commandLatency.record(execution);
            commandCounter.increment();
        } finally {
            activeCommands.decrementAndGet();
        }
    }

    public void recordQuery() {
        queryCounter.increment();
    }
}
```

### 5.2 è§‚æµ‹æ³¨è§£ AOP

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.observation.Observation;
import io.micrometer.observation.ObservationRegistry;
import io.micrometer.observation.annotation.Observed;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.stereotype.Component;

@Aspect
@Component
public class ObservabilityAspect {

    private final ObservationRegistry observationRegistry;

    public ObservabilityAspect(ObservationRegistry observationRegistry) {
        this.observationRegistry = observationRegistry;
    }

    @Around("@annotation(observed)")
    public Object observe(ProceedingJoinPoint pjp, Observed observed) throws Throwable {
        String name = observed.name().isEmpty()
            ? pjp.getSignature().getName()
            : observed.name();

        return Observation.createNotStarted(name, observationRegistry)
            .lowCardinalityKeyValue("class", pjp.getTarget().getClass().getSimpleName())
            .lowCardinalityKeyValue("method", pjp.getSignature().getName())
            .observe(() -> {
                try {
                    return pjp.proceed();
                } catch (Throwable e) {
                    throw new RuntimeException(e);
                }
            });
    }
}

// ä½¿ç”¨ç¤ºä¾‹
// @Observed(name = "process.order")
// public Order processOrder(OrderCommand cmd) {
//     // è‡ªåŠ¨è®°å½•æŒ‡æ ‡å’Œé“¾è·¯
// }
```

---

## å…­ã€åŸºç¡€è®¾æ–½éƒ¨ç½²

### 6.1 Docker Compose

```yaml
# docker-compose-observability.yml
version: '3.8'

services:
  # ============================================
  # Prometheus - æŒ‡æ ‡å­˜å‚¨
  # ============================================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/alert.rules.yml:/etc/prometheus/alert.rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    networks:
      - observability

  # ============================================
  # Loki - æ—¥å¿—å­˜å‚¨
  # ============================================
  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./config/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - observability

  # ============================================
  # Promtail - æ—¥å¿—é‡‡é›†
  # ============================================
  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    volumes:
      - ./config/promtail.yml:/etc/promtail/config.yml
      - ./logs:/var/log/app  # æŒ‚è½½åº”ç”¨æ—¥å¿—ç›®å½•
    command: -config.file=/etc/promtail/config.yml
    networks:
      - observability

  # ============================================
  # Tempo - é“¾è·¯è¿½è¸ªå­˜å‚¨
  # ============================================
  tempo:
    image: grafana/tempo:2.2.0
    container_name: tempo
    ports:
      - "3200:3200"   # Tempo Query
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - ./config/tempo.yml:/etc/tempo/tempo.yml
      - tempo_data:/var/tempo
    command: -config.file=/etc/tempo/tempo.yml
    networks:
      - observability

  # ============================================
  # Grafana - ç»Ÿä¸€å¯è§†åŒ–
  # ============================================
  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
      - loki
      - tempo
    networks:
      - observability

networks:
  observability:
    driver: bridge

volumes:
  prometheus_data:
  loki_data:
  tempo_data:
  grafana_data:
```

### 6.2 Prometheus é…ç½®

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - /etc/prometheus/alert.rules.yml

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'meta-driven'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 5s
    static_configs:
      - targets: ['host.docker.internal:8080']
        labels:
          application: 'meta-driven'
          environment: 'local'
```

### 6.3 Loki é…ç½®

```yaml
# config/loki.yml
auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
```

### 6.4 Promtail é…ç½®

```yaml
# config/promtail.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: meta-driven
    static_configs:
      - targets:
          - localhost
        labels:
          job: meta-driven
          __path__: /var/log/app/*.json
    pipeline_stages:
      - json:
          expressions:
            level: level
            traceId: traceId
            spanId: spanId
            message: message
      - labels:
          level:
          traceId:
```

### 6.5 Tempo é…ç½®

```yaml
# config/tempo.yml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        http:
        grpc:

ingester:
  trace_idle_period: 10s
  max_block_bytes: 1_000_000
  max_block_duration: 5m

compactor:
  compaction:
    compaction_window: 1h
    max_block_bytes: 100_000_000
    block_retention: 1h
    compacted_block_retention: 10m

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
```

### 6.6 Grafana æ•°æ®æºé…ç½®

```yaml
# config/grafana/provisioning/datasources/datasources.yml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true

  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    jsonData:
      derivedFields:
        - datasourceUid: tempo
          matcherRegex: '"traceId":"(\w+)"'
          name: TraceID
          url: '$${__value.raw}'

  - name: Tempo
    type: tempo
    access: proxy
    uid: tempo
    url: http://tempo:3200
    jsonData:
      tracesToLogs:
        datasourceUid: loki
        filterByTraceID: true
      serviceMap:
        datasourceUid: prometheus
```

---

## ä¸ƒã€å…³é”®æŒ‡æ ‡ä¸å‘Šè­¦

### 7.1 æ ¸å¿ƒç›‘æ§æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡å | æè¿° | å‘Šè­¦é˜ˆå€¼ |
|------|--------|------|----------|
| **RED æŒ‡æ ‡** | | | |
| Rate | `http_server_requests_seconds_count` | è¯·æ±‚é€Ÿç‡ | N/A |
| Errors | `http_server_requests_seconds_count{status=~"5.."}` | é”™è¯¯ç‡ | > 1% |
| Duration | `http_server_requests_seconds{quantile="0.99"}` | P99 å»¶è¿Ÿ | > 500ms |
| **JVM æŒ‡æ ‡** | | | |
| Heap | `jvm_memory_used_bytes{area="heap"}` | å †å†…å­˜ä½¿ç”¨ | > 80% |
| GC | `jvm_gc_pause_seconds_max` | GC æš‚åœæ—¶é—´ | > 100ms |
| Threads | `jvm_threads_live_threads` | æ´»è·ƒçº¿ç¨‹æ•° | > 500 |
| **ä¸šåŠ¡æŒ‡æ ‡** | | | |
| Commands | `cqrs_commands_total` | å‘½ä»¤æ€»æ•° | N/A |
| Latency | `cqrs_command_latency_seconds{quantile="0.999"}` | P999 å‘½ä»¤å»¶è¿Ÿ | > 10ms |

### 7.2 å‘Šè­¦è§„åˆ™

```yaml
# config/alert.rules.yml
groups:
  - name: meta-driven-alerts
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
          / sum(rate(http_server_requests_seconds_count[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 1% for 5 minutes"

      - alert: HighP99Latency
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_server_requests_seconds_bucket[5m])) by (le)
          ) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "P99 latency above 500ms"

      - alert: HighGCPause
        expr: jvm_gc_pause_seconds_max > 0.1
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "GC pause time exceeds 100ms"

      - alert: HighHeapUsage
        expr: |
          jvm_memory_used_bytes{area="heap"}
          / jvm_memory_max_bytes{area="heap"} > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Heap usage above 80%"

      - alert: ServiceDown
        expr: up{job="meta-driven"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down"
```

---

## å…«ã€TraceID å…³è”

å®ç°æ—¥å¿—ã€æŒ‡æ ‡ã€é“¾è·¯çš„å…³è”æŸ¥è¯¢ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     TraceID      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚    Tempo    â”‚
â”‚   (Logs)    â”‚                  â”‚  (Traces)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                â”‚
       â”‚ TraceID in JSON               â”‚ Exemplars
       â”‚                                â”‚
       â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Loki     â”‚                  â”‚ Prometheus  â”‚
â”‚ (æ—¥å¿—å­˜å‚¨)   â”‚                  â”‚ (æŒ‡æ ‡å­˜å‚¨)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ—¥å¿—ä¸­è‡ªåŠ¨æ³¨å…¥ TraceID**ï¼š
```json
{
  "@timestamp": "2025-01-15T10:30:00.123Z",
  "level": "INFO",
  "logger": "com.tanggo.fund.metadriven.OrderService",
  "message": "Order processed successfully",
  "traceId": "abc123def456",
  "spanId": "789xyz",
  "app": "meta-driven",
  "orderId": "ORD-001"
}
```

---

## ä¹ã€ä½å»¶è¿Ÿç›‘æ§æŒ‡æ ‡ä½“ç³»

é’ˆå¯¹ä½å»¶è¿Ÿåœºæ™¯ï¼Œé™¤äº†åŸºç¡€çš„ RED æŒ‡æ ‡å¤–ï¼Œéœ€è¦å…³æ³¨ä»¥ä¸‹æ·±åº¦æŒ‡æ ‡ï¼š

### 9.1 æ ¸å¿ƒå»¶è¿ŸæŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ | è¯´æ˜ | å‘Šè­¦é˜ˆå€¼ |
|------|------|------|----------|
| **å°¾å»¶è¿Ÿ** | P99.9 / P99.99 | æç«¯æƒ…å†µå»¶è¿Ÿ | æ ¹æ® SLA è®¾å®š |
| **å»¶è¿ŸæŠ–åŠ¨** | stddev / variance | å»¶è¿Ÿç¨³å®šæ€§ | æŠ–åŠ¨ > å‡å€¼ 50% |
| **æœ€å¤§å»¶è¿Ÿ** | max latency | æœ€åæƒ…å†µ | æ ¹æ®ä¸šåŠ¡å®¹å¿åº¦ |

### 9.2 JVM æ·±åº¦æŒ‡æ ‡

#### GC è¯¦ç»†æŒ‡æ ‡
```yaml
# Prometheus æŒ‡æ ‡
jvm_gc_pause_seconds{action="end of minor GC"}     # Young GC æš‚åœ
jvm_gc_pause_seconds{action="end of major GC"}     # Full GC æš‚åœ
jvm_gc_pause_seconds_max                           # æœ€å¤§ GC æš‚åœ
jvm_gc_pause_seconds_count                         # GC æ¬¡æ•°
jvm_gc_memory_promoted_bytes_total                 # æ™‹å‡åˆ°è€å¹´ä»£çš„å­—èŠ‚æ•°
jvm_gc_memory_allocated_bytes_total                # åˆ†é…é€Ÿç‡
jvm_gc_live_data_size_bytes                        # å­˜æ´»æ•°æ®å¤§å°
```

#### SafePoint æŒ‡æ ‡
```yaml
# éœ€è¦å¼€å¯ JVM å‚æ•°: -XX:+PrintSafepointStatistics
jvm_safepoint_pause_seconds                        # SafePoint æš‚åœæ—¶é—´
jvm_safepoint_count                                # SafePoint æ¬¡æ•°
jvm_time_to_safepoint_seconds                      # åˆ°è¾¾ SafePoint çš„æ—¶é—´
```

#### JIT ç¼–è¯‘æŒ‡æ ‡
```yaml
jvm_compilation_time_ms_total                      # JIT ç¼–è¯‘æ€»æ—¶é—´
jvm_classes_loaded                                 # å·²åŠ è½½ç±»æ•°é‡
jvm_classes_unloaded                               # å¸è½½ç±»æ•°é‡ (åŠ¨æ€ç¼–è¯‘ç›¸å…³)
```

### 9.3 ç³»ç»Ÿçº§æŒ‡æ ‡

#### CPU æŒ‡æ ‡
```yaml
# Node Exporter æŒ‡æ ‡
node_cpu_seconds_total{mode="idle"}                # CPU ç©ºé—²
node_cpu_seconds_total{mode="iowait"}              # I/O ç­‰å¾…
node_cpu_seconds_total{mode="softirq"}             # è½¯ä¸­æ–­æ—¶é—´
node_cpu_seconds_total{mode="steal"}               # è™šæ‹ŸåŒ–å·å–æ—¶é—´

# ä¸Šä¸‹æ–‡åˆ‡æ¢
node_context_switches_total                        # ä¸Šä¸‹æ–‡åˆ‡æ¢æ¬¡æ•°
node_procs_running                                 # è¿è¡Œä¸­è¿›ç¨‹æ•°
```

#### å†…å­˜æŒ‡æ ‡
```yaml
node_memory_MemAvailable_bytes                     # å¯ç”¨å†…å­˜
node_memory_Buffers_bytes                          # ç¼“å†²åŒº
node_memory_Cached_bytes                           # é¡µé¢ç¼“å­˜
node_vmstat_pgmajfault                             # ä¸»ç¼ºé¡µæ¬¡æ•° (å…³é”®!)
node_vmstat_pgfault                                # ç¼ºé¡µæ¬¡æ•°
```

#### ç½‘ç»œæŒ‡æ ‡
```yaml
node_network_receive_packets_total                 # æ¥æ”¶åŒ…æ•°
node_network_transmit_packets_total                # å‘é€åŒ…æ•°
node_network_receive_drop_total                    # æ¥æ”¶ä¸¢åŒ…
node_network_transmit_drop_total                   # å‘é€ä¸¢åŒ…
node_netstat_Tcp_RetransSegs                       # TCP é‡ä¼ 
node_sockstat_TCP_tw                               # TIME_WAIT æ•°é‡
```

### 9.4 ä½å»¶è¿Ÿä¸“é¡¹æŒ‡æ ‡ç»„ä»¶

#### çº³ç§’çº§å»¶è¿ŸæŒ‡æ ‡

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.core.instrument.*;
import org.springframework.stereotype.Component;
import java.time.Duration;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

/**
 * ä½å»¶è¿Ÿåœºæ™¯ä¸“ç”¨æŒ‡æ ‡
 * æä¾›çº³ç§’çº§ç²¾åº¦çš„å»¶è¿Ÿç›‘æ§
 */
@Component
public class LowLatencyMetrics {

    private final Timer processingTimer;
    private final DistributionSummary latencyDistribution;
    private final Counter timeoutCounter;
    private final AtomicLong maxLatencyNanos;
    private final AtomicLong minLatencyNanos;

    public LowLatencyMetrics(MeterRegistry registry) {
        // å¤„ç†æ—¶é—´ Timer (çº³ç§’ç²¾åº¦, æ‰©å±•åˆ° P99.99)
        this.processingTimer = Timer.builder("business.processing.time")
            .description("Business processing time with nanosecond precision")
            .publishPercentiles(0.5, 0.9, 0.95, 0.99, 0.999, 0.9999)
            .publishPercentileHistogram()
            .minimumExpectedValue(Duration.ofNanos(100))
            .maximumExpectedValue(Duration.ofMillis(100))
            .register(registry);

        // å»¶è¿Ÿåˆ†å¸ƒ (å¾®ç§’å•ä½ï¼Œç”¨äºåˆ†æ)
        this.latencyDistribution = DistributionSummary.builder("business.latency.distribution")
            .description("Latency distribution in microseconds")
            .baseUnit("microseconds")
            .publishPercentiles(0.5, 0.9, 0.95, 0.99, 0.999, 0.9999)
            .register(registry);

        // è¶…æ—¶è®¡æ•°
        this.timeoutCounter = Counter.builder("business.timeout.total")
            .description("Number of timeouts")
            .register(registry);

        // æœ€å¤§å»¶è¿Ÿ Gauge (æ»‘åŠ¨çª—å£)
        this.maxLatencyNanos = new AtomicLong(0);
        Gauge.builder("business.latency.max", maxLatencyNanos, AtomicLong::get)
            .description("Maximum latency in current window")
            .baseUnit("nanoseconds")
            .register(registry);

        // æœ€å°å»¶è¿Ÿ Gauge
        this.minLatencyNanos = new AtomicLong(Long.MAX_VALUE);
        Gauge.builder("business.latency.min", minLatencyNanos, AtomicLong::get)
            .description("Minimum latency in current window")
            .baseUnit("nanoseconds")
            .register(registry);
    }

    /**
     * è®°å½•å»¶è¿Ÿ (çº³ç§’çº§)
     */
    public void recordLatency(long startNanos) {
        long durationNanos = System.nanoTime() - startNanos;
        processingTimer.record(durationNanos, TimeUnit.NANOSECONDS);
        latencyDistribution.record(durationNanos / 1000.0); // è½¬å¾®ç§’

        // æ›´æ–°æœ€å¤§/æœ€å°å»¶è¿Ÿ
        maxLatencyNanos.updateAndGet(current -> Math.max(current, durationNanos));
        minLatencyNanos.updateAndGet(current -> Math.min(current, durationNanos));
    }

    /**
     * è®°å½•è¶…æ—¶
     */
    public void recordTimeout() {
        timeoutCounter.increment();
    }

    /**
     * é‡ç½®æ»‘åŠ¨çª—å£ç»Ÿè®¡ (å®šæ—¶è°ƒç”¨)
     */
    public void resetWindow() {
        maxLatencyNanos.set(0);
        minLatencyNanos.set(Long.MAX_VALUE);
    }

    /**
     * è®¡ç®—å»¶è¿ŸæŠ–åŠ¨ (æ ‡å‡†å·®è¿‘ä¼¼)
     */
    public double getLatencyJitter() {
        long max = maxLatencyNanos.get();
        long min = minLatencyNanos.get();
        if (min == Long.MAX_VALUE) return 0;
        return (max - min) / 2.0;
    }
}
```

#### çº¿ç¨‹æ± ç›‘æ§æŒ‡æ ‡

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.core.instrument.*;
import org.springframework.stereotype.Component;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

/**
 * çº¿ç¨‹æ± æ·±åº¦ç›‘æ§
 * ç”¨äºå‘ç°çº¿ç¨‹ç«äº‰å’Œé˜Ÿåˆ—ç§¯å‹é—®é¢˜
 */
@Component
public class ThreadPoolMetrics {

    private final Timer queueWaitTimer;
    private final Counter rejectedCounter;

    public ThreadPoolMetrics(MeterRegistry registry) {
        this.queueWaitTimer = Timer.builder("threadpool.queue.wait.time")
            .description("Time spent waiting in queue")
            .publishPercentiles(0.5, 0.95, 0.99, 0.999)
            .register(registry);

        this.rejectedCounter = Counter.builder("threadpool.rejected.total")
            .description("Rejected task count")
            .register(registry);
    }

    /**
     * æ³¨å†Œçº¿ç¨‹æ± ç›‘æ§
     */
    public void registerExecutor(String name, ThreadPoolExecutor executor, MeterRegistry registry) {
        // é˜Ÿåˆ—å¤§å°
        Gauge.builder("threadpool.queue.size", executor, e -> e.getQueue().size())
            .description("Current queue size")
            .tag("name", name)
            .register(registry);

        // æ´»è·ƒçº¿ç¨‹æ•°
        Gauge.builder("threadpool.active.count", executor, ThreadPoolExecutor::getActiveCount)
            .description("Active thread count")
            .tag("name", name)
            .register(registry);

        // æ± å¤§å°
        Gauge.builder("threadpool.pool.size", executor, ThreadPoolExecutor::getPoolSize)
            .description("Current pool size")
            .tag("name", name)
            .register(registry);

        // ä»»åŠ¡å®Œæˆæ•°
        FunctionCounter.builder("threadpool.completed.total", executor,
                ThreadPoolExecutor::getCompletedTaskCount)
            .description("Completed task count")
            .tag("name", name)
            .register(registry);

        // é˜Ÿåˆ—å‰©ä½™å®¹é‡
        Gauge.builder("threadpool.queue.remaining", executor,
                e -> e.getQueue().remainingCapacity())
            .description("Queue remaining capacity")
            .tag("name", name)
            .register(registry);
    }

    /**
     * è®°å½•é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
     */
    public void recordQueueWait(long waitNanos) {
        queueWaitTimer.record(waitNanos, TimeUnit.NANOSECONDS);
    }

    /**
     * è®°å½•æ‹’ç»ä»»åŠ¡
     */
    public void recordRejection() {
        rejectedCounter.increment();
    }
}
```

#### é”ç«äº‰ç›‘æ§

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.core.instrument.*;
import org.springframework.stereotype.Component;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Lock;
import java.util.function.Supplier;

/**
 * é”ç«äº‰ç›‘æ§
 * ç”¨äºå‘ç°é”äº‰ç”¨å¯¼è‡´çš„å»¶è¿Ÿ
 */
@Component
public class LockContentionMetrics {

    private final Timer lockAcquisitionTime;
    private final Counter lockContentionCount;
    private final Counter lockTimeoutCount;

    public LockContentionMetrics(MeterRegistry registry) {
        this.lockAcquisitionTime = Timer.builder("lock.acquisition.time")
            .description("Time to acquire lock")
            .publishPercentiles(0.5, 0.95, 0.99, 0.999)
            .register(registry);

        this.lockContentionCount = Counter.builder("lock.contention.total")
            .description("Lock contention count (failed tryLock)")
            .register(registry);

        this.lockTimeoutCount = Counter.builder("lock.timeout.total")
            .description("Lock acquisition timeout count")
            .register(registry);
    }

    /**
     * å¸¦ç›‘æ§çš„é”æ‰§è¡Œ
     */
    public <T> T measureLock(Lock lock, Supplier<T> action) {
        long start = System.nanoTime();
        boolean acquired = lock.tryLock();

        if (!acquired) {
            lockContentionCount.increment();
            lock.lock();
        }

        try {
            lockAcquisitionTime.record(System.nanoTime() - start, TimeUnit.NANOSECONDS);
            return action.get();
        } finally {
            lock.unlock();
        }
    }

    /**
     * å¸¦è¶…æ—¶çš„é”æ‰§è¡Œ
     */
    public <T> T measureLockWithTimeout(Lock lock, long timeoutMs, Supplier<T> action)
            throws InterruptedException {
        long start = System.nanoTime();
        boolean acquired = lock.tryLock(timeoutMs, TimeUnit.MILLISECONDS);

        if (!acquired) {
            lockTimeoutCount.increment();
            throw new IllegalStateException("Lock acquisition timeout");
        }

        try {
            lockAcquisitionTime.record(System.nanoTime() - start, TimeUnit.NANOSECONDS);
            return action.get();
        } finally {
            lock.unlock();
        }
    }
}
```

#### å†…å­˜åˆ†é…è¿½è¸ª

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.core.instrument.*;
import org.springframework.stereotype.Component;
import java.lang.management.ManagementFactory;
import java.lang.management.MemoryPoolMXBean;
import java.util.List;

/**
 * å†…å­˜åˆ†é…ç›‘æ§
 * ç”¨äºè¿½è¸ªåˆ†é…é€Ÿç‡å’Œ GC å‹åŠ›
 */
@Component
public class MemoryAllocationMetrics {

    public MemoryAllocationMetrics(MeterRegistry registry) {
        // Eden åŒºä½¿ç”¨ç‡ (åˆ†é…é€Ÿç‡æŒ‡æ ‡)
        List<MemoryPoolMXBean> pools = ManagementFactory.getMemoryPoolMXBeans();

        for (MemoryPoolMXBean pool : pools) {
            String poolName = pool.getName().toLowerCase().replace(" ", "_");

            // å†…å­˜æ± ä½¿ç”¨é‡
            Gauge.builder("jvm.memory.pool.used", pool, p -> p.getUsage().getUsed())
                .description("Memory pool used bytes")
                .tag("pool", poolName)
                .baseUnit("bytes")
                .register(registry);

            // å†…å­˜æ± å³°å€¼
            Gauge.builder("jvm.memory.pool.peak", pool, p -> p.getPeakUsage().getUsed())
                .description("Memory pool peak used bytes")
                .tag("pool", poolName)
                .baseUnit("bytes")
                .register(registry);
        }

        // å †å¤–å†…å­˜ç›‘æ§
        Gauge.builder("jvm.buffer.memory.used",
                () -> ManagementFactory.getMemoryMXBean().getNonHeapMemoryUsage().getUsed())
            .description("Non-heap memory used")
            .baseUnit("bytes")
            .register(registry);
    }
}
```

### 9.5 ä½å»¶è¿Ÿå‘Šè­¦è§„åˆ™

```yaml
# config/alert.rules.yml ä½å»¶è¿Ÿä¸“é¡¹å‘Šè­¦
groups:
  - name: low-latency-alerts
    rules:
      # P99.9 å»¶è¿Ÿå‘Šè­¦
      - alert: HighP999Latency
        expr: |
          histogram_quantile(0.999,
            sum(rate(http_server_requests_seconds_bucket{application="meta-driven"}[5m])) by (le)
          ) > 0.01
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "P99.9 latency above 10ms"
          description: "P99.9 latency is {{ $value | humanizeDuration }}"

      # P99.99 å»¶è¿Ÿå‘Šè­¦ (æç«¯æƒ…å†µ)
      - alert: HighP9999Latency
        expr: |
          histogram_quantile(0.9999,
            sum(rate(http_server_requests_seconds_bucket{application="meta-driven"}[5m])) by (le)
          ) > 0.1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "P99.99 latency above 100ms"

      # å»¶è¿ŸæŠ–åŠ¨å‘Šè­¦
      - alert: HighLatencyJitter
        expr: |
          stddev_over_time(
            histogram_quantile(0.99,
              sum(rate(http_server_requests_seconds_bucket{application="meta-driven"}[1m])) by (le)
            )[5m:]
          )
          /
          avg_over_time(
            histogram_quantile(0.99,
              sum(rate(http_server_requests_seconds_bucket{application="meta-driven"}[1m])) by (le)
            )[5m:]
          ) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency jitter detected"
          description: "Latency stddev > 50% of mean"

      # GC é¢‘ç‡å‘Šè­¦
      - alert: HighGCFrequency
        expr: |
          rate(jvm_gc_pause_seconds_count{application="meta-driven"}[5m]) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "GC frequency above 1/s"
          description: "High GC frequency may cause latency spikes"

      # Young GC æš‚åœæ—¶é—´å‘Šè­¦
      - alert: HighYoungGCPause
        expr: |
          jvm_gc_pause_seconds_max{application="meta-driven",action=~".*minor.*|.*young.*"} > 0.01
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Young GC pause above 10ms"

      # å†…å­˜åˆ†é…é€Ÿç‡å‘Šè­¦
      - alert: HighAllocationRate
        expr: |
          rate(jvm_gc_memory_allocated_bytes_total{application="meta-driven"}[5m]) > 500000000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Memory allocation rate above 500MB/s"
          description: "High allocation rate indicates potential GC pressure"

      # ä¸»ç¼ºé¡µå‘Šè­¦ (ç³»ç»Ÿçº§)
      - alert: HighMajorPageFault
        expr: |
          rate(node_vmstat_pgmajfault[5m]) > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High major page fault rate"
          description: "Major page faults cause significant latency"

      # ä¸Šä¸‹æ–‡åˆ‡æ¢å‘Šè­¦
      - alert: HighContextSwitches
        expr: |
          rate(node_context_switches_total[5m]) > 100000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High context switch rate (>100k/s)"

      # SafePoint æš‚åœå‘Šè­¦
      - alert: HighSafepointPause
        expr: |
          jvm_safepoint_pause_seconds_max > 0.01
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "SafePoint pause above 10ms"

      # çº¿ç¨‹æ± é˜Ÿåˆ—ç§¯å‹
      - alert: ThreadPoolQueueBacklog
        expr: |
          threadpool_queue_size{application="meta-driven"} > 100
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Thread pool queue backlog detected"
          description: "Queue size: {{ $value }}"

      # çº¿ç¨‹æ± æ‹’ç»ä»»åŠ¡
      - alert: ThreadPoolRejection
        expr: |
          rate(threadpool_rejected_total{application="meta-driven"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Thread pool rejecting tasks"

      # é”ç«äº‰å‘Šè­¦
      - alert: HighLockContention
        expr: |
          rate(lock_contention_total{application="meta-driven"}[5m]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High lock contention rate"

      # TCP é‡ä¼ å‘Šè­¦
      - alert: HighTCPRetransmission
        expr: |
          rate(node_netstat_Tcp_RetransSegs[5m]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High TCP retransmission rate"

      # è¶…æ—¶è®¡æ•°å‘Šè­¦
      - alert: BusinessTimeout
        expr: |
          rate(business_timeout_total{application="meta-driven"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Business timeout detected"
```

### 9.6 ä½å»¶è¿Ÿç›‘æ§ Dashboard å…³é”®é¢æ¿

| é¢æ¿ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **å»¶è¿Ÿåˆ†å¸ƒ** | P50/P90/P95/P99/P99.9/P99.99 | å…¨é¢å±•ç¤ºå»¶è¿Ÿåˆ†å¸ƒ |
| **å»¶è¿Ÿçƒ­åŠ›å›¾** | Histogram heatmap | å¯è§†åŒ–å»¶è¿Ÿåˆ†å¸ƒå˜åŒ– |
| **å»¶è¿ŸæŠ–åŠ¨** | stddev over time | å»¶è¿Ÿç¨³å®šæ€§ |
| **GC æš‚åœæ—¶é—´** | gc_pause_seconds by action | æŒ‰ GC ç±»å‹åˆ†ç±» |
| **GC é¢‘ç‡** | gc_pause_count rate | è¯†åˆ« GC é£æš´ |
| **å†…å­˜åˆ†é…é€Ÿç‡** | allocated_bytes/s | è¯†åˆ«åˆ†é…çƒ­ç‚¹ |
| **CPU åˆ©ç”¨ç‡åˆ†è§£** | user/system/iowait/softirq | è¯†åˆ« CPU ç“¶é¢ˆ |
| **ä¸Šä¸‹æ–‡åˆ‡æ¢** | context_switches/s | è¯†åˆ«çº¿ç¨‹ç«äº‰ |
| **ç½‘ç»œå»¶è¿Ÿ** | tcp_retrans/dropped | ç½‘ç»œå±‚é—®é¢˜ |
| **çº¿ç¨‹æ± çŠ¶æ€** | queue_size/active_count | è¯†åˆ«ç§¯å‹ |
| **é”ç«äº‰ç‡** | contention_count/s | è¯†åˆ«é”äº‰ç”¨ |

### 9.7 Prometheus é‡‡é›†ä¼˜åŒ–

```yaml
# config/prometheus.yml ä½å»¶è¿Ÿåœºæ™¯ä¼˜åŒ–é…ç½®
global:
  scrape_interval: 5s          # æ›´é¢‘ç¹é‡‡é›†
  evaluation_interval: 5s

scrape_configs:
  - job_name: 'meta-driven'
    scrape_interval: 5s
    scrape_timeout: 3s         # è¶…æ—¶æ§åˆ¶
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8080']
        labels:
          application: 'meta-driven'
          environment: 'local'

  # Node Exporter (ç³»ç»Ÿçº§æŒ‡æ ‡)
  - job_name: 'node'
    scrape_interval: 5s
    static_configs:
      - targets: ['host.docker.internal:9100']

  # ä½¿ç”¨ Exemplars å…³è” Trace
  - job_name: 'meta-driven-exemplars'
    scrape_interval: 5s
    enable_http2: true
    static_configs:
      - targets: ['host.docker.internal:8080']
```

### 9.8 ä½å»¶è¿Ÿé…ç½®ä¼˜åŒ–

```yaml
# ç”Ÿäº§ç¯å¢ƒä½å»¶è¿Ÿé…ç½®
management:
  tracing:
    sampling:
      probability: 0.1  # 10% é‡‡æ ·ç‡ï¼Œé™ä½å¼€é”€

  metrics:
    distribution:
      percentiles-histogram:
        http.server.requests: true
        business.processing.time: true
      percentiles:
        http.server.requests: 0.5, 0.9, 0.95, 0.99, 0.999, 0.9999
        business.processing.time: 0.5, 0.9, 0.95, 0.99, 0.999, 0.9999
      minimum-expected-value:
        http.server.requests: 100us
        business.processing.time: 100ns
      maximum-expected-value:
        http.server.requests: 1s
        business.processing.time: 100ms
    export:
      prometheus:
        step: 5s  # æ›´é¢‘ç¹åˆ·æ–°
```

```xml
<!-- logback ä½å»¶è¿Ÿé…ç½® -->
<appender name="ASYNC_JSON" class="ch.qos.logback.classic.AsyncAppender">
    <queueSize>4096</queueSize>
    <discardingThreshold>0</discardingThreshold>
    <neverBlock>true</neverBlock>  <!-- å…³é”®ï¼šæ°¸ä¸é˜»å¡ -->
    <includeCallerData>false</includeCallerData>  <!-- ç¦ç”¨è°ƒç”¨è€…ä¿¡æ¯ï¼Œå‡å°‘å¼€é”€ -->
    <appender-ref ref="JSON_FILE"/>
</appender>
```

### 9.9 JVM ä½å»¶è¿Ÿå‚æ•°

```bash
# ä½å»¶è¿Ÿ JVM å‚æ•°
JAVA_OPTS="
  # GC é€‰æ‹© (ä¸‰é€‰ä¸€)
  # é€‰é¡¹ 1: G1GC (å¹³è¡¡)
  -XX:+UseG1GC
  -XX:MaxGCPauseMillis=10
  -XX:G1HeapRegionSize=4m

  # é€‰é¡¹ 2: ZGC (è¶…ä½å»¶è¿Ÿï¼Œéœ€è¦ JDK 15+)
  # -XX:+UseZGC
  # -XX:+ZGenerational

  # é€‰é¡¹ 3: Shenandoah (ä½å»¶è¿Ÿ)
  # -XX:+UseShenandoahGC

  # é€šç”¨ä¼˜åŒ–
  -XX:+AlwaysPreTouch
  -XX:+UseNUMA
  -XX:+DisableExplicitGC
  -XX:-UseBiasedLocking
  -XX:+UseTransparentHugePages

  # SafePoint ä¼˜åŒ–
  -XX:+UnlockDiagnosticVMOptions
  -XX:GuaranteedSafepointInterval=0

  # é¢„çƒ­å’Œç¼–è¯‘
  -XX:+TieredCompilation
  -XX:CompileThreshold=1000

  # ç›‘æ§æ”¯æŒ
  -XX:+PrintGCDetails
  -XX:+PrintGCDateStamps
  -Xlog:gc*:file=gc.log:time,uptime:filecount=5,filesize=10m
  -Xlog:safepoint*:file=safepoint.log:time,uptime
"
```

---

## åã€å¿«é€Ÿå¯åŠ¨

```bash
# 1. åˆ›å»ºé…ç½®ç›®å½•
mkdir -p config/grafana/provisioning/datasources

# 2. å¤åˆ¶é…ç½®æ–‡ä»¶ï¼ˆæŒ‰ç…§ä¸Šè¿°é…ç½®åˆ›å»ºï¼‰
# config/prometheus.yml
# config/loki.yml
# config/promtail.yml
# config/tempo.yml
# config/alert.rules.yml
# config/grafana/provisioning/datasources/datasources.yml

# 3. å¯åŠ¨å¯è§‚æµ‹æ€§åŸºç¡€è®¾æ–½
docker-compose -f docker-compose-observability.yml up -d

# 4. å¯åŠ¨åº”ç”¨
./mvnw spring-boot:run

# 5. è®¿é—®é¢æ¿
# Grafana: http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9090
# åº”ç”¨æŒ‡æ ‡: http://localhost:8080/actuator/prometheus
```

---

## åä¸€ã€Grafana Dashboard æ¨è

| Dashboard | ID | è¯´æ˜ |
|-----------|-----|------|
| Spring Boot Statistics | 12900 | Spring Boot åº”ç”¨ç›‘æ§ |
| JVM Micrometer | 4701 | JVM è¯¦ç»†æŒ‡æ ‡ |
| Prometheus Stats | 2 | Prometheus è‡ªèº«ç›‘æ§ |

å¯¼å…¥æ–¹å¼ï¼šGrafana â†’ Dashboards â†’ Import â†’ è¾“å…¥ ID

---

## åäºŒã€Alertmanager å‘Šè­¦é€šçŸ¥

### 12.1 Alertmanager é…ç½®

```yaml
# config/alertmanager.yml
global:
  # å…¨å±€é…ç½®
  resolve_timeout: 5m
  # SMTP é…ç½®ï¼ˆé‚®ä»¶é€šçŸ¥ï¼‰
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'password'

# è·¯ç”±è§„åˆ™
route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default-receiver'
  routes:
    # Critical å‘Šè­¦ç«‹å³é€šçŸ¥
    - match:
        severity: critical
      receiver: 'critical-receiver'
      group_wait: 0s
    # Warning å‘Šè­¦æ±‡æ€»é€šçŸ¥
    - match:
        severity: warning
      receiver: 'warning-receiver'
      group_wait: 5m

# æ¥æ”¶å™¨é…ç½®
receivers:
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://localhost:8080/webhook/alert'
        send_resolved: true

  - name: 'critical-receiver'
    # é’‰é’‰æœºå™¨äºº
    webhook_configs:
      - url: 'https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN'
        send_resolved: true
    # é‚®ä»¶é€šçŸ¥
    email_configs:
      - to: 'oncall@example.com'
        send_resolved: true

  - name: 'warning-receiver'
    # Slack é€šçŸ¥
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        send_resolved: true

# æŠ‘åˆ¶è§„åˆ™ï¼ˆCritical å­˜åœ¨æ—¶æŠ‘åˆ¶ Warningï¼‰
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname']
```

### 12.2 é’‰é’‰å‘Šè­¦æ¨¡æ¿

```yaml
# config/dingtalk-template.yml
# éœ€è¦é…åˆ prometheus-webhook-dingtalk ä½¿ç”¨
templates:
  - name: 'dingtalk.default.message'
    text: |
      {{ if gt (len .Alerts.Firing) 0 }}
      ## ğŸ”¥ å‘Šè­¦è§¦å‘ ({{ len .Alerts.Firing }})
      {{ range .Alerts.Firing }}
      **å‘Šè­¦åç§°**: {{ .Labels.alertname }}
      **ä¸¥é‡çº§åˆ«**: {{ .Labels.severity }}
      **å‘Šè­¦æ‘˜è¦**: {{ .Annotations.summary }}
      **å‘Šè­¦è¯¦æƒ…**: {{ .Annotations.description }}
      **è§¦å‘æ—¶é—´**: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      ---
      {{ end }}
      {{ end }}

      {{ if gt (len .Alerts.Resolved) 0 }}
      ## âœ… å‘Šè­¦æ¢å¤ ({{ len .Alerts.Resolved }})
      {{ range .Alerts.Resolved }}
      **å‘Šè­¦åç§°**: {{ .Labels.alertname }}
      **æ¢å¤æ—¶é—´**: {{ .EndsAt.Format "2006-01-02 15:04:05" }}
      ---
      {{ end }}
      {{ end }}
```

### 12.3 Docker Compose æ·»åŠ  Alertmanager

```yaml
  # ============================================
  # Alertmanager - å‘Šè­¦é€šçŸ¥
  # ============================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - observability
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================
  # é’‰é’‰å‘Šè­¦ç½‘å…³ï¼ˆå¯é€‰ï¼‰
  # ============================================
  dingtalk:
    image: timonwong/prometheus-webhook-dingtalk:v2.1.0
    container_name: dingtalk
    ports:
      - "8060:8060"
    volumes:
      - ./config/dingtalk.yml:/etc/prometheus-webhook-dingtalk/config.yml
    command:
      - '--config.file=/etc/prometheus-webhook-dingtalk/config.yml'
    networks:
      - observability
```

### 12.4 æ›´æ–° Prometheus é…ç½®è¿æ¥ Alertmanager

```yaml
# config/prometheus.yml æ·»åŠ 
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093
```

---

## åä¸‰ã€æ–¹æ¡ˆéªŒè¯

### 13.1 éªŒè¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        éªŒè¯é‡‘å­—å¡”                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 4: ç«¯åˆ°ç«¯éªŒè¯ (E2E)                                           â”‚
â”‚    - æ¨¡æ‹Ÿæ•…éšœ â†’ å‘Šè­¦è§¦å‘ â†’ é€šçŸ¥åˆ°è¾¾                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 3: å…³è”æ€§éªŒè¯                                                 â”‚
â”‚    - TraceID ä»æ—¥å¿—è·³è½¬åˆ° Trace                                      â”‚
â”‚    - Trace å…³è”åˆ° Metrics                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 2: æ•°æ®æµéªŒè¯                                                 â”‚
â”‚    - App â†’ Prometheus æŒ‡æ ‡å¯è§                                      â”‚
â”‚    - App â†’ Loki æ—¥å¿—å¯æŸ¥                                            â”‚
â”‚    - App â†’ Tempo é“¾è·¯å¯è¿½è¸ª                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 1: åŸºç¡€è®¾æ–½éªŒè¯                                               â”‚
â”‚    - æ‰€æœ‰å®¹å™¨æ­£å¸¸è¿è¡Œ                                                â”‚
â”‚    - ç«¯å£å¯è®¿é—®                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 13.2 éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# scripts/verify-observability.sh

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

print_status() {
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}[PASS]${NC} $2"
    else
        echo -e "${RED}[FAIL]${NC} $2"
    fi
}

print_header() {
    echo -e "\n${YELLOW}========== $1 ==========${NC}"
}

# ============================================
# Level 1: åŸºç¡€è®¾æ–½éªŒè¯
# ============================================
print_header "Level 1: åŸºç¡€è®¾æ–½éªŒè¯"

# 1.1 æ£€æŸ¥å®¹å™¨çŠ¶æ€
echo "æ£€æŸ¥ Docker å®¹å™¨çŠ¶æ€..."
containers=("prometheus" "loki" "tempo" "grafana" "alertmanager")
for container in "${containers[@]}"; do
    status=$(docker inspect -f '{{.State.Running}}' $container 2>/dev/null || echo "false")
    if [ "$status" = "true" ]; then
        print_status 0 "$container è¿è¡Œä¸­"
    else
        print_status 1 "$container æœªè¿è¡Œ"
    fi
done

# 1.2 æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
echo -e "\næ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€..."

check_health() {
    local name=$1
    local url=$2
    local code=$(curl -s -o /dev/null -w "%{http_code}" "$url" 2>/dev/null || echo "000")
    if [ "$code" = "200" ] || [ "$code" = "204" ]; then
        print_status 0 "$name å¥åº· (HTTP $code)"
        return 0
    else
        print_status 1 "$name ä¸å¥åº· (HTTP $code)"
        return 1
    fi
}

check_health "Prometheus" "http://localhost:9090/-/healthy"
check_health "Loki" "http://localhost:3100/ready"
check_health "Tempo" "http://localhost:3200/ready"
check_health "Grafana" "http://localhost:3000/api/health"
check_health "Alertmanager" "http://localhost:9093/-/healthy"

# ============================================
# Level 2: æ•°æ®æµéªŒè¯
# ============================================
print_header "Level 2: æ•°æ®æµéªŒè¯"

# 2.1 éªŒè¯ Prometheus æŠ“å–ç›®æ ‡
echo "æ£€æŸ¥ Prometheus æŠ“å–ç›®æ ‡..."
targets=$(curl -s "http://localhost:9090/api/v1/targets" | jq -r '.data.activeTargets[] | select(.labels.job=="meta-driven") | .health')
if [ "$targets" = "up" ]; then
    print_status 0 "Prometheus æŠ“å– meta-driven æ­£å¸¸"
else
    print_status 1 "Prometheus æŠ“å– meta-driven å¤±è´¥"
fi

# 2.2 éªŒè¯åº”ç”¨æŒ‡æ ‡ç«¯ç‚¹
echo "æ£€æŸ¥åº”ç”¨æŒ‡æ ‡ç«¯ç‚¹..."
metrics=$(curl -s "http://localhost:8080/actuator/prometheus" 2>/dev/null | grep -c "jvm_memory" || echo "0")
if [ "$metrics" -gt 0 ]; then
    print_status 0 "åº”ç”¨æŒ‡æ ‡ç«¯ç‚¹æ­£å¸¸ (æ‰¾åˆ° $metrics ä¸ª JVM æŒ‡æ ‡)"
else
    print_status 1 "åº”ç”¨æŒ‡æ ‡ç«¯ç‚¹å¼‚å¸¸"
fi

# 2.3 éªŒè¯ Loki æ—¥å¿—
echo "æ£€æŸ¥ Loki æ—¥å¿—..."
log_count=$(curl -s 'http://localhost:3100/loki/api/v1/query?query={job="meta-driven"}' | jq '.data.result | length')
if [ "$log_count" -gt 0 ]; then
    print_status 0 "Loki æ—¥å¿—æ­£å¸¸ (æ‰¾åˆ° $log_count ä¸ªæ—¥å¿—æµ)"
else
    print_status 1 "Loki æœªæ”¶åˆ°æ—¥å¿—"
fi

# 2.4 éªŒè¯ Tempo é“¾è·¯
echo "æ£€æŸ¥ Tempo é“¾è·¯..."
trace_count=$(curl -s "http://localhost:3200/api/search?limit=1" | jq '.traces | length' 2>/dev/null || echo "0")
if [ "$trace_count" -gt 0 ]; then
    print_status 0 "Tempo é“¾è·¯æ­£å¸¸"
else
    print_status 1 "Tempo æœªæ”¶åˆ°é“¾è·¯æ•°æ®"
fi

# ============================================
# Level 3: å…³è”æ€§éªŒè¯
# ============================================
print_header "Level 3: å…³è”æ€§éªŒè¯"

# 3.1 éªŒè¯æ—¥å¿—ä¸­åŒ…å« TraceID
echo "æ£€æŸ¥æ—¥å¿—ä¸­çš„ TraceID..."
trace_in_log=$(curl -s 'http://localhost:3100/loki/api/v1/query?query={job="meta-driven"}' | jq -r '.data.result[0].values[0][1]' 2>/dev/null | jq -r '.traceId // empty')
if [ -n "$trace_in_log" ] && [ "$trace_in_log" != "null" ]; then
    print_status 0 "æ—¥å¿—åŒ…å« TraceID: $trace_in_log"

    # 3.2 éªŒè¯ TraceID åœ¨ Tempo ä¸­å¯æŸ¥
    echo "éªŒè¯ TraceID åœ¨ Tempo ä¸­..."
    tempo_trace=$(curl -s "http://localhost:3200/api/traces/$trace_in_log" | jq '.batches | length' 2>/dev/null || echo "0")
    if [ "$tempo_trace" -gt 0 ]; then
        print_status 0 "TraceID å…³è”éªŒè¯æˆåŠŸ"
    else
        print_status 1 "TraceID åœ¨ Tempo ä¸­æœªæ‰¾åˆ°"
    fi
else
    print_status 1 "æ—¥å¿—ä¸­æœªæ‰¾åˆ° TraceID"
fi

# ============================================
# Level 4: å‘Šè­¦éªŒè¯
# ============================================
print_header "Level 4: å‘Šè­¦éªŒè¯"

# 4.1 æ£€æŸ¥å‘Šè­¦è§„åˆ™åŠ è½½
echo "æ£€æŸ¥å‘Šè­¦è§„åˆ™..."
rules_count=$(curl -s "http://localhost:9090/api/v1/rules" | jq '.data.groups | length')
if [ "$rules_count" -gt 0 ]; then
    print_status 0 "å‘Šè­¦è§„åˆ™å·²åŠ è½½ ($rules_count ç»„)"
else
    print_status 1 "æœªåŠ è½½å‘Šè­¦è§„åˆ™"
fi

# 4.2 æ£€æŸ¥ Alertmanager è¿æ¥
echo "æ£€æŸ¥ Alertmanager è¿æ¥..."
am_status=$(curl -s "http://localhost:9090/api/v1/alertmanagers" | jq '.data.activeAlertmanagers | length')
if [ "$am_status" -gt 0 ]; then
    print_status 0 "Alertmanager å·²è¿æ¥"
else
    print_status 1 "Alertmanager æœªè¿æ¥"
fi

# ============================================
# æ±‡æ€»
# ============================================
print_header "éªŒè¯å®Œæˆ"
echo "è¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡ºï¼Œç¡®ä¿æ‰€æœ‰æ£€æŸ¥é¡¹é€šè¿‡"
```

### 13.3 æµ‹è¯•ç«¯ç‚¹ (ç”¨äºéªŒè¯)

```java
package com.tanggo.fund.metadriven.observability;

import io.micrometer.tracing.Tracer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.slf4j.MDC;
import org.springframework.web.bind.annotation.*;
import java.util.Map;
import java.util.concurrent.ThreadLocalRandom;

/**
 * å¯è§‚æµ‹æ€§éªŒè¯æµ‹è¯•ç«¯ç‚¹
 * ç”¨äºéªŒè¯ Metrics/Logging/Tracing æ˜¯å¦æ­£å¸¸å·¥ä½œ
 */
@RestController
@RequestMapping("/test/observability")
public class ObservabilityTestController {

    private static final Logger log = LoggerFactory.getLogger(ObservabilityTestController.class);
    private final Tracer tracer;

    public ObservabilityTestController(Tracer tracer) {
        this.tracer = tracer;
    }

    /**
     * å¥åº·æ£€æŸ¥ç«¯ç‚¹
     */
    @GetMapping("/health")
    public Map<String, Object> health() {
        log.info("Health check endpoint called");
        return Map.of(
            "status", "UP",
            "traceId", getCurrentTraceId(),
            "timestamp", System.currentTimeMillis()
        );
    }

    /**
     * è·å–å½“å‰ Trace ä¿¡æ¯
     */
    @GetMapping("/trace")
    public Map<String, String> getTraceInfo() {
        String traceId = getCurrentTraceId();
        String spanId = MDC.get("spanId");
        log.info("Trace info endpoint called, traceId={}, spanId={}", traceId, spanId);
        return Map.of(
            "traceId", traceId != null ? traceId : "N/A",
            "spanId", spanId != null ? spanId : "N/A"
        );
    }

    /**
     * æ¨¡æ‹Ÿé”™è¯¯ï¼ˆç”¨äºæµ‹è¯•å‘Šè­¦ï¼‰
     */
    @GetMapping("/error")
    public void triggerError() {
        log.error("Simulated error for observability test");
        throw new RuntimeException("Test error - This is intentional for testing alerts");
    }

    /**
     * æ¨¡æ‹Ÿæ…¢è¯·æ±‚ï¼ˆç”¨äºæµ‹è¯•å»¶è¿Ÿå‘Šè­¦ï¼‰
     */
    @GetMapping("/slow")
    public Map<String, Object> triggerSlow(@RequestParam(defaultValue = "2000") long delayMs)
            throws InterruptedException {
        log.warn("Slow endpoint called, delay={}ms", delayMs);
        Thread.sleep(delayMs);
        return Map.of(
            "message", "slow response",
            "delayMs", delayMs,
            "traceId", getCurrentTraceId()
        );
    }

    /**
     * æ¨¡æ‹Ÿéšæœºå»¶è¿Ÿï¼ˆç”¨äºç”Ÿæˆå»¶è¿Ÿåˆ†å¸ƒæ•°æ®ï¼‰
     */
    @GetMapping("/random-latency")
    public Map<String, Object> randomLatency() throws InterruptedException {
        // 90% è¯·æ±‚ 10-50ms, 9% è¯·æ±‚ 100-300ms, 1% è¯·æ±‚ 500-2000ms
        int random = ThreadLocalRandom.current().nextInt(100);
        long delay;
        if (random < 90) {
            delay = ThreadLocalRandom.current().nextLong(10, 50);
        } else if (random < 99) {
            delay = ThreadLocalRandom.current().nextLong(100, 300);
        } else {
            delay = ThreadLocalRandom.current().nextLong(500, 2000);
        }

        Thread.sleep(delay);
        log.debug("Random latency request, delay={}ms", delay);

        return Map.of(
            "delayMs", delay,
            "percentile", random < 90 ? "P90" : (random < 99 ? "P99" : "P999")
        );
    }

    /**
     * ç”Ÿæˆæµ‹è¯•æ—¥å¿—ï¼ˆä¸åŒçº§åˆ«ï¼‰
     */
    @PostMapping("/logs")
    public Map<String, String> generateLogs(@RequestParam(defaultValue = "10") int count) {
        for (int i = 0; i < count; i++) {
            int level = i % 4;
            switch (level) {
                case 0 -> log.debug("Test DEBUG log #{}", i);
                case 1 -> log.info("Test INFO log #{}", i);
                case 2 -> log.warn("Test WARN log #{}", i);
                case 3 -> log.error("Test ERROR log #{}", i);
            }
        }
        return Map.of(
            "message", "Generated " + count + " logs",
            "traceId", getCurrentTraceId()
        );
    }

    /**
     * æ¨¡æ‹Ÿå†…å­˜å‹åŠ›ï¼ˆç”¨äºæµ‹è¯•å†…å­˜å‘Šè­¦ï¼‰
     */
    @GetMapping("/memory-pressure")
    public Map<String, Object> memoryPressure(@RequestParam(defaultValue = "100") int sizeMB) {
        log.warn("Memory pressure test, allocating {}MB", sizeMB);

        // åˆ†é…å†…å­˜ï¼ˆæ³¨æ„ï¼šè¿™åªæ˜¯æµ‹è¯•ç”¨ï¼Œä¸è¦åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼‰
        byte[][] arrays = new byte[sizeMB][];
        for (int i = 0; i < sizeMB; i++) {
            arrays[i] = new byte[1024 * 1024]; // 1MB
        }

        Runtime runtime = Runtime.getRuntime();
        long usedMemory = (runtime.totalMemory() - runtime.freeMemory()) / (1024 * 1024);
        long maxMemory = runtime.maxMemory() / (1024 * 1024);

        // ç«‹å³é‡Šæ”¾
        arrays = null;
        System.gc();

        return Map.of(
            "allocatedMB", sizeMB,
            "usedMemoryMB", usedMemory,
            "maxMemoryMB", maxMemory,
            "usagePercent", (usedMemory * 100.0) / maxMemory
        );
    }

    private String getCurrentTraceId() {
        if (tracer.currentSpan() != null && tracer.currentSpan().context() != null) {
            return tracer.currentSpan().context().traceId();
        }
        return MDC.get("traceId");
    }
}
```

### 13.4 éªŒè¯æ£€æŸ¥æ¸…å•

| éªŒè¯é¡¹ | éªŒè¯æ–¹æ³• | é¢„æœŸç»“æœ | é€šè¿‡ |
|--------|----------|----------|------|
| **åŸºç¡€è®¾æ–½** | | | |
| Docker å®¹å™¨è¿è¡Œ | `docker ps` | æ‰€æœ‰å®¹å™¨ Up | [ ] |
| Prometheus å¥åº· | `curl localhost:9090/-/healthy` | 200 OK | [ ] |
| Loki å¥åº· | `curl localhost:3100/ready` | 200 OK | [ ] |
| Tempo å¥åº· | `curl localhost:3200/ready` | 200 OK | [ ] |
| Grafana å¥åº· | `curl localhost:3000/api/health` | 200 OK | [ ] |
| **æ•°æ®æµ** | | | |
| åº”ç”¨æŒ‡æ ‡æš´éœ² | `curl localhost:8080/actuator/prometheus` | è¿”å›æŒ‡æ ‡ | [ ] |
| Prometheus æŠ“å– | Prometheus UI â†’ Targets | meta-driven UP | [ ] |
| Loki æ”¶åˆ°æ—¥å¿— | Grafana Explore â†’ Loki | æœ‰æ—¥å¿— | [ ] |
| Tempo æ”¶åˆ°é“¾è·¯ | Grafana Explore â†’ Tempo | æœ‰ Traces | [ ] |
| **å…³è”æ€§** | | | |
| æ—¥å¿—å« TraceID | æŸ¥çœ‹ JSON æ—¥å¿— | traceId å­—æ®µéç©º | [ ] |
| æ—¥å¿—è·³è½¬ Trace | ç‚¹å‡» Loki æ—¥å¿—ä¸­çš„ TraceID | è·³è½¬åˆ° Tempo | [ ] |
| Trace å…³è”æ—¥å¿— | Tempo è¯¦æƒ…é¡µ | æ˜¾ç¤ºå…³è”æ—¥å¿— | [ ] |
| **å‘Šè­¦** | | | |
| å‘Šè­¦è§„åˆ™åŠ è½½ | Prometheus UI â†’ Alerts | æ˜¾ç¤ºè§„åˆ™ | [ ] |
| Alertmanager è¿æ¥ | Prometheus UI â†’ Status | AM å·²è¿æ¥ | [ ] |
| å‘Šè­¦è§¦å‘æµ‹è¯• | `curl localhost:8080/test/observability/error` | å‘Šè­¦è§¦å‘ | [ ] |
| å‘Šè­¦é€šçŸ¥åˆ°è¾¾ | æ£€æŸ¥é’‰é’‰/é‚®ä»¶ | æ”¶åˆ°é€šçŸ¥ | [ ] |
| **æ€§èƒ½** | | | |
| P99 å»¶è¿ŸåŸºçº¿ | å‹æµ‹å¯¹æ¯” | å¢åŠ  < 5% | [ ] |

---

## åå››ã€æ€§èƒ½åŸºå‡†æµ‹è¯•

### 14.1 åŸºå‡†æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# scripts/benchmark-observability.sh

# ä¾èµ–: wrk, jq

BASE_URL="http://localhost:8080"
DURATION="30s"
THREADS=4
CONNECTIONS=100

print_header() {
    echo -e "\n========== $1 =========="
}

# æµ‹è¯•ç«¯ç‚¹
TEST_ENDPOINT="/test/observability/random-latency"

print_header "åŸºå‡†æµ‹è¯•é…ç½®"
echo "URL: $BASE_URL$TEST_ENDPOINT"
echo "Duration: $DURATION"
echo "Threads: $THREADS"
echo "Connections: $CONNECTIONS"

print_header "åœºæ™¯ 1: åŸºçº¿æµ‹è¯• (é‡‡æ ·ç‡ 100%)"
echo "ç¡®ä¿ management.tracing.sampling.probability=1.0"
read -p "æŒ‰ Enter ç»§ç»­..."

wrk -t$THREADS -c$CONNECTIONS -d$DURATION --latency "$BASE_URL$TEST_ENDPOINT" | tee baseline_100.txt

print_header "åœºæ™¯ 2: é‡‡æ ·ç‡ 10%"
echo "ä¿®æ”¹ management.tracing.sampling.probability=0.1 å¹¶é‡å¯åº”ç”¨"
read -p "æŒ‰ Enter ç»§ç»­..."

wrk -t$THREADS -c$CONNECTIONS -d$DURATION --latency "$BASE_URL$TEST_ENDPOINT" | tee baseline_10.txt

print_header "åœºæ™¯ 3: é‡‡æ ·ç‡ 1%"
echo "ä¿®æ”¹ management.tracing.sampling.probability=0.01 å¹¶é‡å¯åº”ç”¨"
read -p "æŒ‰ Enter ç»§ç»­..."

wrk -t$THREADS -c$CONNECTIONS -d$DURATION --latency "$BASE_URL$TEST_ENDPOINT" | tee baseline_1.txt

print_header "åœºæ™¯ 4: å…³é—­ Tracing"
echo "ä¿®æ”¹ management.tracing.enabled=false å¹¶é‡å¯åº”ç”¨"
read -p "æŒ‰ Enter ç»§ç»­..."

wrk -t$THREADS -c$CONNECTIONS -d$DURATION --latency "$BASE_URL$TEST_ENDPOINT" | tee baseline_off.txt

print_header "ç»“æœå¯¹æ¯”"
echo "é‡‡æ ·ç‡ 100%:"
grep "Latency" baseline_100.txt
grep "Req/Sec" baseline_100.txt

echo -e "\né‡‡æ ·ç‡ 10%:"
grep "Latency" baseline_10.txt
grep "Req/Sec" baseline_10.txt

echo -e "\né‡‡æ ·ç‡ 1%:"
grep "Latency" baseline_1.txt
grep "Req/Sec" baseline_1.txt

echo -e "\nå…³é—­ Tracing:"
grep "Latency" baseline_off.txt
grep "Req/Sec" baseline_off.txt
```

### 14.2 æ€§èƒ½åŸºå‡†æ•°æ®æ¨¡æ¿

| åœºæ™¯ | é‡‡æ ·ç‡ | QPS | P50 | P95 | P99 | P999 | å¼€é”€ |
|------|--------|-----|-----|-----|-----|------|------|
| åŸºçº¿ (æ— å¯è§‚æµ‹) | N/A | - | - | - | - | - | 0% |
| ä»… Metrics | N/A | - | - | - | - | - | ~1% |
| Metrics + Tracing | 100% | - | - | - | - | - | ~5% |
| Metrics + Tracing | 10% | - | - | - | - | - | ~2% |
| Metrics + Tracing | 1% | - | - | - | - | - | ~1% |
| å®Œæ•´æ–¹æ¡ˆ | 10% | - | - | - | - | - | ~3% |

**æ€§èƒ½ç›®æ ‡**:
- P99 å»¶è¿Ÿå¢åŠ  < 5%
- QPS ä¸‹é™ < 5%
- å†…å­˜å¢åŠ  < 10%

---

## åäº”ã€æ›´æ–°åçš„ Docker Compose (å®Œæ•´ç‰ˆ)

```yaml
# docker-compose-observability.yml
version: '3.8'

services:
  # ============================================
  # Prometheus - æŒ‡æ ‡å­˜å‚¨
  # ============================================
  prometheus:
    image: prom/prometheus:v2.53.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/alert.rules.yml:/etc/prometheus/alert.rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    networks:
      - observability
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ============================================
  # Alertmanager - å‘Šè­¦é€šçŸ¥
  # ============================================
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - observability
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # ============================================
  # Loki - æ—¥å¿—å­˜å‚¨
  # ============================================
  loki:
    image: grafana/loki:3.0.0
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./config/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - observability
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # ============================================
  # Promtail - æ—¥å¿—é‡‡é›†
  # ============================================
  promtail:
    image: grafana/promtail:3.0.0
    container_name: promtail
    volumes:
      - ./config/promtail.yml:/etc/promtail/config.yml
      - ./logs:/var/log/app
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - observability
    depends_on:
      loki:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # ============================================
  # Tempo - é“¾è·¯è¿½è¸ªå­˜å‚¨
  # ============================================
  tempo:
    image: grafana/tempo:2.5.0
    container_name: tempo
    ports:
      - "3200:3200"   # Tempo Query
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - ./config/tempo.yml:/etc/tempo/tempo.yml
      - tempo_data:/var/tempo
    command: -config.file=/etc/tempo/tempo.yml
    networks:
      - observability
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3200/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # ============================================
  # Grafana - ç»Ÿä¸€å¯è§†åŒ–
  # ============================================
  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor,correlations
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-piechart-panel
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    networks:
      - observability
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
      tempo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

networks:
  observability:
    driver: bridge

volumes:
  prometheus_data:
    driver: local
  alertmanager_data:
    driver: local
  loki_data:
    driver: local
  tempo_data:
    driver: local
  grafana_data:
    driver: local
```

---

## åå…­ã€Grafana Dashboard JSON

### 16.1 Dashboard é…ç½®è‡ªåŠ¨åŠ è½½

```yaml
# config/grafana/provisioning/dashboards/dashboards.yml
apiVersion: 1
providers:
  - name: 'default'
    orgId: 1
    folder: 'Meta-Driven'
    type: file
    disableDeletion: false
    updateIntervalSeconds: 30
    options:
      path: /var/lib/grafana/dashboards
```

### 16.2 åº”ç”¨æ¦‚è§ˆ Dashboard

å°†ä»¥ä¸‹ JSON ä¿å­˜åˆ° `config/grafana/dashboards/meta-driven-overview.json`:

```json
{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "mappings": [],
          "thresholds": { "mode": "absolute", "steps": [{ "color": "green", "value": null }] },
          "unit": "short"
        }
      },
      "gridPos": { "h": 4, "w": 6, "x": 0, "y": 0 },
      "id": 1,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "pluginVersion": "11.0.0",
      "targets": [
        {
          "expr": "sum(rate(http_server_requests_seconds_count{application=\"meta-driven\"}[5m]))",
          "legendFormat": "RPS",
          "refId": "A"
        }
      ],
      "title": "è¯·æ±‚é€Ÿç‡ (RPS)",
      "type": "stat"
    },
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 0.01 },
              { "color": "red", "value": 0.05 }
            ]
          },
          "unit": "percentunit"
        }
      },
      "gridPos": { "h": 4, "w": 6, "x": 6, "y": 0 },
      "id": 2,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(rate(http_server_requests_seconds_count{application=\"meta-driven\",status=~\"5..\"}[5m])) / sum(rate(http_server_requests_seconds_count{application=\"meta-driven\"}[5m]))",
          "legendFormat": "Error Rate",
          "refId": "A"
        }
      ],
      "title": "é”™è¯¯ç‡",
      "type": "stat"
    },
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 0.1 },
              { "color": "red", "value": 0.5 }
            ]
          },
          "unit": "s"
        }
      },
      "gridPos": { "h": 4, "w": 6, "x": 12, "y": 0 },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.99, sum(rate(http_server_requests_seconds_bucket{application=\"meta-driven\"}[5m])) by (le))",
          "legendFormat": "P99",
          "refId": "A"
        }
      ],
      "title": "P99 å»¶è¿Ÿ",
      "type": "stat"
    },
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 0.7 },
              { "color": "red", "value": 0.9 }
            ]
          },
          "unit": "percentunit"
        }
      },
      "gridPos": { "h": 4, "w": 6, "x": 18, "y": 0 },
      "id": 4,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(jvm_memory_used_bytes{application=\"meta-driven\",area=\"heap\"}) / sum(jvm_memory_max_bytes{application=\"meta-driven\",area=\"heap\"})",
          "legendFormat": "Heap Usage",
          "refId": "A"
        }
      ],
      "title": "å †å†…å­˜ä½¿ç”¨ç‡",
      "type": "stat"
    },
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": { "legend": false, "tooltip": false, "viz": false },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": { "type": "linear" },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": { "group": "A", "mode": "none" },
            "thresholdsStyle": { "mode": "off" }
          },
          "mappings": [],
          "thresholds": { "mode": "absolute", "steps": [{ "color": "green", "value": null }] },
          "unit": "s"
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 4 },
      "id": 5,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom", "showLegend": true },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.5, sum(rate(http_server_requests_seconds_bucket{application=\"meta-driven\"}[5m])) by (le))",
          "legendFormat": "P50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_server_requests_seconds_bucket{application=\"meta-driven\"}[5m])) by (le))",
          "legendFormat": "P95",
          "refId": "B"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(http_server_requests_seconds_bucket{application=\"meta-driven\"}[5m])) by (le))",
          "legendFormat": "P99",
          "refId": "C"
        },
        {
          "expr": "histogram_quantile(0.999, sum(rate(http_server_requests_seconds_bucket{application=\"meta-driven\"}[5m])) by (le))",
          "legendFormat": "P999",
          "refId": "D"
        }
      ],
      "title": "è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "prometheus" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": { "legend": false, "tooltip": false, "viz": false },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": { "type": "linear" },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": { "group": "A", "mode": "none" },
            "thresholdsStyle": { "mode": "off" }
          },
          "mappings": [],
          "thresholds": { "mode": "absolute", "steps": [{ "color": "green", "value": null }] },
          "unit": "bytes"
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 4 },
      "id": 6,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom", "showLegend": true },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "targets": [
        {
          "expr": "sum(jvm_memory_used_bytes{application=\"meta-driven\",area=\"heap\"}) by (id)",
          "legendFormat": "{{id}}",
          "refId": "A"
        }
      ],
      "title": "JVM å †å†…å­˜",
      "type": "timeseries"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["meta-driven", "spring-boot"],
  "templating": { "list": [] },
  "time": { "from": "now-1h", "to": "now" },
  "timepicker": {},
  "timezone": "",
  "title": "Meta-Driven åº”ç”¨æ¦‚è§ˆ",
  "uid": "meta-driven-overview",
  "version": 1,
  "weekStart": ""
}
```

---

## åä¸ƒã€å®æ–½æ£€æŸ¥æ¸…å• (æ›´æ–°ç‰ˆ)

### é˜¶æ®µ 1: åŸºç¡€è®¾æ–½
- [ ] åˆ›å»ºé…ç½®ç›®å½•ç»“æ„
- [ ] ç¼–å†™æ‰€æœ‰é…ç½®æ–‡ä»¶
- [ ] å¯åŠ¨ Docker Compose
- [ ] éªŒè¯æ‰€æœ‰å®¹å™¨å¥åº·

### é˜¶æ®µ 2: åº”ç”¨é›†æˆ
- [ ] æ·»åŠ  Maven ä¾èµ–
- [ ] é…ç½® application.yml
- [ ] åˆ›å»º logback-spring.xml
- [ ] å®ç°è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡
- [ ] æ·»åŠ æµ‹è¯•ç«¯ç‚¹

### é˜¶æ®µ 3: éªŒè¯
- [ ] è¿è¡ŒéªŒè¯è„šæœ¬
- [ ] éªŒè¯ Prometheus æŠ“å–
- [ ] éªŒè¯ Loki æ—¥å¿—é‡‡é›†
- [ ] éªŒè¯ Tempo é“¾è·¯è¿½è¸ª
- [ ] éªŒè¯ TraceID å…³è”

### é˜¶æ®µ 4: å‘Šè­¦
- [ ] é…ç½® Alertmanager
- [ ] é…ç½®å‘Šè­¦é€šçŸ¥æ¸ é“
- [ ] æµ‹è¯•å‘Šè­¦è§¦å‘
- [ ] éªŒè¯å‘Šè­¦é€šçŸ¥åˆ°è¾¾

### é˜¶æ®µ 5: æ€§èƒ½éªŒè¯
- [ ] è¿è¡ŒåŸºå‡†æµ‹è¯•
- [ ] è®°å½•æ€§èƒ½æ•°æ®
- [ ] éªŒè¯å»¶è¿Ÿå¼€é”€ < 5%
- [ ] ç¡®å®šæœ€ä¼˜é‡‡æ ·ç‡

### é˜¶æ®µ 6: è¿ç»´å°±ç»ª
- [ ] å¯¼å…¥ Grafana Dashboard
- [ ] é…ç½®æ•°æ®å¤‡ä»½ç­–ç•¥
- [ ] ç¼–å†™è¿ç»´æ–‡æ¡£
- [ ] åŸ¹è®­å›¢é˜Ÿæˆå‘˜